{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "#\n",
    "# Copyright (C) 2024 Analog Devices, Inc. All Rights Reserved.\n",
    "# This software is proprietary to Analog Devices, Inc. and its licensors.\n",
    "#\n",
    "###################################################################################################\n",
    "\"\"\"\n",
    "Auto Encoder Network\n",
    "\"\"\"\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import ai8x\n",
    "\n",
    "\n",
    "class CNN_BASE(nn.Module):\n",
    "    \"\"\"\n",
    "    Auto Encoder Network\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_channels=2,  # pylint: disable=unused-argument\n",
    "                 bias=True,  # pylint: disable=unused-argument\n",
    "                 weight_init=\"kaiming\",  # pylint: disable=unused-argument\n",
    "                 num_classes=0,  # pylint: disable=unused-argument\n",
    "                 **kwargs):  # pylint: disable=unused-argument\n",
    "        super().__init__()\n",
    "\n",
    "    def initWeights(self, weight_init=\"kaiming\"):\n",
    "        \"\"\"\n",
    "        Auto Encoder Weight Initialization\n",
    "        \"\"\"\n",
    "        weight_init = weight_init.lower()\n",
    "        assert weight_init in ('kaiming', 'xavier', 'glorot')\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if weight_init == \"kaiming\":\n",
    "                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "                elif weight_init in ('glorot', 'xavier'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "            elif isinstance(m, nn.ConvTranspose2d):\n",
    "                if weight_init == \"kaiming\":\n",
    "                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "                elif weight_init in ('glorot', 'xavier'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                if weight_init == \"kaiming\":\n",
    "                    nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "                elif weight_init in ('glorot', 'xavier'):\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "\n",
    "class AI85AutoEncoder(CNN_BASE):\n",
    "    \"\"\"\n",
    "    Neural Network that has depthwise convolutions to reduce input dimensions.\n",
    "    Filters work across individual axis data first.\n",
    "    Output of 1D Conv layer is then flattened before being fed to fully connected layers\n",
    "    Fully connected layers down sample the data to a bottleneck. This completes the encoder.\n",
    "    The decoder is then the same in reverse\n",
    "\n",
    "    Input Shape: [BATCH_SZ, FFT_LEN, N_AXES] -> [BATCH_SZ, 256, 3] = [N, N_CHANNELS, SIGNAL_LEN]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_channels=128,\n",
    "                 dimensions=(128, 1),  # pylint: disable=unused-argument\n",
    "                 num_classes=1,  # pylint: disable=unused-argument\n",
    "                 bias=True,\n",
    "                 weight_init=\"kaiming\",\n",
    "                 batchNorm=True,\n",
    "                 bottleNeckDim=4,\n",
    "                 **kwargs):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        print(\"Batchnorm setting in model = \", batchNorm)\n",
    "\n",
    "        weight_init = weight_init.lower()\n",
    "        assert weight_init in ('kaiming', 'xavier', 'glorot')\n",
    "\n",
    "        # Num channels is equal to the length of FFTs here\n",
    "        self.num_channels = num_channels\n",
    "        # self.n_axes = n_axes\n",
    "\n",
    "        S = 1\n",
    "        P = 0\n",
    "\n",
    "        self.transform_layer = ai8x.FusedConv1dReLU(num_channels, 128, 1, stride=S, padding=0, bias=bias, **kwargs)\n",
    "\n",
    "        # ----- DECODER ----- #\n",
    "        # Kernel in 1st layer looks at 1 axis at a time. Output width = input width\n",
    "        self.en_conv1 = ai8x.FusedConv1dBNReLU(128, 64, 1, stride=S, padding=P, dilation=1, bias=bias, **kwargs)\n",
    "        self.en_conv1 = ai8x.FusedConv1dReLU(128, 64, 1, stride=S, padding=P, dilation=1, bias=bias, **kwargs)\n",
    "        self.layer1_n_in = 128\n",
    "        self.layer1_n_out = 64\n",
    "\n",
    "        # Kernel in 2nd layer looks at 3 axes at once. Output Width = 1. Depth=n_out\n",
    "        self.en_conv2 = ai8x.FusedAvgPoolConv1dBNReLU(64, 32, 1, stride=S, padding=P, dilation=1, bias=bias, **kwargs)\n",
    "        self.en_conv2 = ai8x.FusedAvgPoolConv1dReLU(64, 32, 1, stride=S, padding=P, dilation=1, bias=bias, **kwargs)\n",
    "        self.layer2_n_in = 64\n",
    "        self.layer2_n_out = 32\n",
    "\n",
    "        self.en_lin1 = ai8x.FusedLinearReLU(32, 32, bias=bias, **kwargs)\n",
    "        # ----- END OF DECODER ----- #\n",
    "\n",
    "        # ---- BOTTLENECK ---- #\n",
    "        # n_in = n_out\n",
    "        n_out = 32\n",
    "        self.bottleNeckDim = bottleNeckDim\n",
    "        n_out = self.bottleNeckDim\n",
    "        self.en_lin2 = ai8x.Linear(32, 32, bias=0, **kwargs)\n",
    "        # ---- END OF BOTTLENECK ---- #\n",
    "\n",
    "        # ----- ENCODER ----- #\n",
    "        self.de_lin1 = ai8x.FusedLinearReLU(32, 32, bias=bias, **kwargs)\n",
    "        self.de_lin2 = ai8x.FusedLinearReLU(32, 96, bias=bias, **kwargs)\n",
    "        self.out_lin = ai8x.Linear(96, 128, bias=0, **kwargs)\n",
    "        # ----- END OF ENCODER ----- #\n",
    "\n",
    "        self.initWeights(weight_init)\n",
    "\n",
    "    def forward(self, x, return_bottleneck=False):\n",
    "        \"\"\"Forward prop\"\"\"\n",
    "        x = self.en_conv1(x)\n",
    "        x = self.en_conv2(x)\n",
    "        x = x.view(x.shape[0], x.shape[1])\n",
    "        x = self.en_lin1(x)\n",
    "        x = self.en_lin2(x)\n",
    "\n",
    "        if return_bottleneck:\n",
    "            return x\n",
    "\n",
    "        x = self.de_lin1(x)\n",
    "        x = self.de_lin2(x)\n",
    "        x = self.out_lin(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def ai85autoencoder(pretrained=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Constructs an Autoencoder model\n",
    "    \"\"\"\n",
    "    assert not pretrained\n",
    "    return AI85AutoEncoder(**kwargs)\n",
    "\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        'name': 'ai85autoencoder',\n",
    "        'min_input': 1,\n",
    "        'dim': 1,\n",
    "    }\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
